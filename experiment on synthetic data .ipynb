{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment on synthetic data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No treatment effect\n",
    "# size of treatment < < size of control \n",
    "# size of treatment ≈ size of control \n",
    "# different distribution of treatment / control \n",
    "# same dis of treatment / control "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from scipy.stats import norm, sem\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats.stats import pearsonr\n",
    "from numpy.random import default_rng\n",
    "import random\n",
    "pd.set_option('display.max_columns', 100)\n",
    "from resample import * \n",
    "from metalearner import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Extension: For get_data_with_same_distribution , we always generate one dimensional feature x ∈ (0,1), for w = 0, y = x + 1. for w = 1, y = x + 2. So the ite and ate are both 1. In addition,  # treatment sample = # control sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_data_class = resample_from_synthetic_data(n_sample= 1000000)\n",
    "d = syn_data_class.get_data_with_same_distribution(ratio = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_learner = Slearner(baselearner=LinearRegression(), is_regressor=True)\n",
    "s_learner.fit(X = np.array(d['X']).reshape(len(d['X']),1), treatment = np.array(d['W']), \n",
    "              y =  np.array(d['Y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ite, yhat_ts, yhat_cs, rmse = s_learner.get_ite(X =np.array(d['X']).reshape(len(d['X']),1), treatment = d['W'], y =  d['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for S learner:  0.9999999999999966\n"
     ]
    }
   ],
   "source": [
    "print('ATE for S learner: ', np.mean(ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_learner = Tlearner(LinearRegression(),LinearRegression(), is_regressor= True)\n",
    "t_learner.fit(X = np.array(d['X']).reshape(-1,1), treatment = np.array(d['W']), \n",
    "              y =  np.array(d['Y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ite, yhat_ts, yhat_cs, rmse = t_learner.get_ite(X = np.array(d['X']).reshape(-1,1), treatment = d['W'], y =  d['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for T learner:  1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "print('ATE for T learner: ', np.mean(ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_learner = Xlearner(LinearRegression(),\n",
    "                     propensity_model = LogisticRegression(),\n",
    "                    is_regressor= True)\n",
    "x_learner.fit(X = np.array(d['X']).reshape(-1,1), treatment = np.array(d['W']), \n",
    "              y =  np.array(d['Y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ite, yhat_ts, yhat_cs, rmse = x_learner.get_ite(X = np.array(d['X']).reshape(-1,1), treatment = d['W'], y =  d['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for X learner:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('ATE for X learner: ', np.mean(ite))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can draw conclusion from above result that when control and treatment groups are from the same simple distribution \n",
    "and when the data sizes are equal, the three metalearners perform equally well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paper claims:  X-learner performs particularly well when the treatment group sizes are very unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_data_class = resample_from_synthetic_data(n_sample= 1000000)\n",
    "d = syn_data_class.get_data_with_same_distribution(ratio = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = syn_data_class.get_data_with_same_distribution(ratio = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W</th>\n",
       "      <th>Y0</th>\n",
       "      <th>Y1</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>990000</th>\n",
       "      <td>1</td>\n",
       "      <td>1.139203</td>\n",
       "      <td>2.139203</td>\n",
       "      <td>0.139203</td>\n",
       "      <td>2.139203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990001</th>\n",
       "      <td>1</td>\n",
       "      <td>1.540330</td>\n",
       "      <td>2.540330</td>\n",
       "      <td>0.540330</td>\n",
       "      <td>2.540330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990002</th>\n",
       "      <td>1</td>\n",
       "      <td>1.360063</td>\n",
       "      <td>2.360063</td>\n",
       "      <td>0.360063</td>\n",
       "      <td>2.360063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990003</th>\n",
       "      <td>1</td>\n",
       "      <td>1.323327</td>\n",
       "      <td>2.323327</td>\n",
       "      <td>0.323327</td>\n",
       "      <td>2.323327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990004</th>\n",
       "      <td>1</td>\n",
       "      <td>1.831549</td>\n",
       "      <td>2.831549</td>\n",
       "      <td>0.831549</td>\n",
       "      <td>2.831549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>1</td>\n",
       "      <td>1.812929</td>\n",
       "      <td>2.812929</td>\n",
       "      <td>0.812929</td>\n",
       "      <td>2.812929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>1</td>\n",
       "      <td>1.491826</td>\n",
       "      <td>2.491826</td>\n",
       "      <td>0.491826</td>\n",
       "      <td>2.491826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>1</td>\n",
       "      <td>1.701604</td>\n",
       "      <td>2.701604</td>\n",
       "      <td>0.701604</td>\n",
       "      <td>2.701604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>1</td>\n",
       "      <td>1.589628</td>\n",
       "      <td>2.589628</td>\n",
       "      <td>0.589628</td>\n",
       "      <td>2.589628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>1</td>\n",
       "      <td>1.536729</td>\n",
       "      <td>2.536729</td>\n",
       "      <td>0.536729</td>\n",
       "      <td>2.536729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        W        Y0        Y1         X         Y\n",
       "990000  1  1.139203  2.139203  0.139203  2.139203\n",
       "990001  1  1.540330  2.540330  0.540330  2.540330\n",
       "990002  1  1.360063  2.360063  0.360063  2.360063\n",
       "990003  1  1.323327  2.323327  0.323327  2.323327\n",
       "990004  1  1.831549  2.831549  0.831549  2.831549\n",
       "...    ..       ...       ...       ...       ...\n",
       "999995  1  1.812929  2.812929  0.812929  2.812929\n",
       "999996  1  1.491826  2.491826  0.491826  2.491826\n",
       "999997  1  1.701604  2.701604  0.701604  2.701604\n",
       "999998  1  1.589628  2.589628  0.589628  2.589628\n",
       "999999  1  1.536729  2.536729  0.536729  2.536729\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[d['W'] == 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for S learner:  1.0\n"
     ]
    }
   ],
   "source": [
    "s_learner = Slearner(baselearner=LinearRegression(), is_regressor=True)\n",
    "s_learner.fit(X = np.array(d['X']).reshape(len(d['X']),1), treatment = np.array(d['W']), \n",
    "              y =  np.array(d['Y']))\n",
    "ite, yhat_ts, yhat_cs, rmse = s_learner.get_ite(X =np.array(d_test['X']).reshape(len(d_test['X']),1), treatment = d_test['W'], y =  d['Y'])\n",
    "print('ATE for S learner: ', np.mean(ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for T learner:  1.0\n"
     ]
    }
   ],
   "source": [
    "t_learner = Tlearner(LinearRegression(),LinearRegression(), is_regressor= True)\n",
    "t_learner.fit(X = np.array(d['X']).reshape(-1,1), treatment = np.array(d['W']), \n",
    "              y =  np.array(d['Y']))\n",
    "\n",
    "ite, yhat_ts, yhat_cs, rmse = t_learner.get_ite(X = np.array(d_test['X']).reshape(-1,1), treatment = d_test['W'], y =  d_test['Y'])\n",
    "\n",
    "print('ATE for T learner: ', np.mean(ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for X learner:  1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "x_learner = Xlearner(LinearRegression(),\n",
    "                     propensity_model = LogisticRegression(),\n",
    "                    is_regressor= True)\n",
    "x_learner.fit(X = np.array(d['X']).reshape(-1,1), treatment = np.array(d['W']), \n",
    "              y =  np.array(d['Y']))\n",
    "ite, yhat_ts, yhat_cs, rmse = x_learner.get_ite(X = np.array(d_test['X']).reshape(-1,1), treatment = d_test['W'], y =  d_test['Y'])\n",
    "\n",
    "print('ATE for X learner: ', np.mean(ite))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All three metalearners perform well "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paper claims:  X-learner performs well for two extreme cases where: 1. CATE functions are very complex and 2. treatmnent effect is 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  complex function w = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complex CATE function (i.e.: when w= 1, true distribution is quite complex)\n",
    "\n",
    "syn_data_class = resample_from_synthetic_data(n_sample= 1000)\n",
    "d = syn_data_class.get_data_with_diff_distribution(ratio = 0.1)\n",
    "d_test = syn_data_class.get_data_with_diff_distribution(ratio = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True ate for this data is:  1.7322758574140962\n"
     ]
    }
   ],
   "source": [
    "# For every x, true ite is 3 + np.abs(x*x*x - x) - (x+1) = 2 - x + np.abs(x*x*x - x)\n",
    "# calculate true ate first \n",
    "true_ite = [2 - x + np.abs(x*x*x - x) for x in d_test['X']]\n",
    "true_ate = np.mean(true_ite)\n",
    "print('True ate for this data is: ', true_ate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for S learner:  1.7353553289558623\n"
     ]
    }
   ],
   "source": [
    "s_learner = Slearner(baselearner=LinearRegression(), is_regressor=True)\n",
    "s_learner.fit(X = np.array(d['X']).reshape(len(d['X']),1), treatment = np.array(d['W']), \n",
    "              y =  np.array(d['Y']))\n",
    "ite, yhat_ts, yhat_cs, rmse = s_learner.get_ite(X =np.array(d_test['X']).reshape(len(d_test['X']),1), treatment = d_test['W'], y =  d['Y'])\n",
    "print('ATE for S learner: ', np.mean(ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for T learner:  1.715321689046918\n"
     ]
    }
   ],
   "source": [
    "t_learner = Tlearner(LinearRegression(),LinearRegression(), is_regressor= True)\n",
    "t_learner.fit(X = np.array(d['X']).reshape(-1,1), treatment = np.array(d['W']), \n",
    "              y =  np.array(d['Y']))\n",
    "\n",
    "ite, yhat_ts, yhat_cs, rmse = t_learner.get_ite(X = np.array(d_test['X']).reshape(-1,1), treatment = d_test['W'], y =  d_test['Y'])\n",
    "\n",
    "print('ATE for T learner: ', np.mean(ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for X learner:  1.7153216890469185\n"
     ]
    }
   ],
   "source": [
    "x_learner = Xlearner(LinearRegression(),\n",
    "                     propensity_model = LogisticRegression(),\n",
    "                    is_regressor= True)\n",
    "x_learner.fit(X = np.array(d['X']).reshape(-1,1), treatment = np.array(d['W']), \n",
    "              y =  np.array(d['Y']))\n",
    "ite, yhat_ts, yhat_cs, rmse = x_learner.get_ite(X = np.array(d_test['X']).reshape(-1,1), treatment = d_test['W'], y =  d_test['Y'])\n",
    "\n",
    "print('ATE for X learner: ', np.mean(ite))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### treatment effect = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_data_class = resample_from_synthetic_data(n_sample= 1000)\n",
    "d = syn_data_class.get_data_with_zero_treatment_effect(ratio = 0.5)\n",
    "d_test = syn_data_class.get_data_with_zero_treatment_effect(ratio = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for S learner:  -8.881784197001253e-19\n"
     ]
    }
   ],
   "source": [
    "s_learner = Slearner(baselearner=LinearRegression(), is_regressor=True)\n",
    "s_learner.fit(X = np.array(d['X']).reshape(len(d['X']),1), treatment = np.array(d['W']), \n",
    "              y =  np.array(d['Y']))\n",
    "ite, yhat_ts, yhat_cs, rmse = s_learner.get_ite(X =np.array(d_test['X']).reshape(len(d_test['X']),1), treatment = d_test['W'], y =  d['Y'])\n",
    "print('ATE for S learner: ', np.mean(ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for T learner:  -8.526512829121202e-17\n"
     ]
    }
   ],
   "source": [
    "t_learner = Tlearner(LinearRegression(),LinearRegression(), is_regressor= True)\n",
    "t_learner.fit(X = np.array(d['X']).reshape(-1,1), treatment = np.array(d['W']), \n",
    "              y =  np.array(d['Y']))\n",
    "\n",
    "ite, yhat_ts, yhat_cs, rmse = t_learner.get_ite(X = np.array(d_test['X']).reshape(-1,1), treatment = d_test['W'], y =  d_test['Y'])\n",
    "\n",
    "print('ATE for T learner: ', np.mean(ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for X learner:  -4.234797938131524e-17\n"
     ]
    }
   ],
   "source": [
    "x_learner = Xlearner(LinearRegression(),\n",
    "                     propensity_model = LogisticRegression(),\n",
    "                    is_regressor= True)\n",
    "x_learner.fit(X = np.array(d['X']).reshape(-1,1), treatment = np.array(d['W']), \n",
    "              y =  np.array(d['Y']))\n",
    "ite, yhat_ts, yhat_cs, rmse = x_learner.get_ite(X = np.array(d_test['X']).reshape(-1,1), treatment = d_test['W'], y =  d_test['Y'])\n",
    "\n",
    "print('ATE for X learner: ', np.mean(ite))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: X-learner performs well on both tasks, but T and S learners perform very well too. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments with GOTV data (we do not know the true ate of data ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing \n",
    "\n",
    "df = pd.read_csv('GerberGreenLarimer_APSR_2008_social_pressure.csv')\n",
    "df = df[df['treatment'].isin([' Control',' Neighbors'])]\n",
    "\n",
    "# df = pd.read_csv('GerberGreenLarimer_APSR_2008_social_pressure.csv')\n",
    "df['treatment'] = np.where(df.treatment == ' Control',0,1)\n",
    "df['voted'] = np.where(df.voted == 'Yes', 1, 0)\n",
    "df['sex'] = np.where(df.sex == 'male',1, 0)\n",
    "df['g2000'] = np.where(df.g2000 == 'yes', 1, 0)\n",
    "df['g2002'] = np.where(df.g2002 == 'yes', 1, 0)\n",
    "df['g2004'] = np.where(df.g2004 == 'yes', 1, 0)\n",
    "df['p2000'] = np.where(df.p2000 == 'yes', 1, 0)\n",
    "df['p2002'] = np.where(df.p2002 == 'yes', 1, 0)\n",
    "df['p2004'] = np.where(df.p2004 == 'Yes', 1, 0)\n",
    "\n",
    "cts_variables_names = [\"yob\",\"treatment\",\"cluster\",\"hh_id\",\"hh_size\",\"numberofnames\",\"p2004_mean\",\"g2004_mean\"]\n",
    "binary_variables_names = [\"sex\",\"g2000\", \"g2002\", \"p2000\", \"p2002\", \"p2004\"]\n",
    "# for column in binary_variables_names:\n",
    "#     if column == 'sex':\n",
    "#         df[column] = np.where(df[column] == ' male',1,0)\n",
    "#     else:\n",
    "#         df[column] = df[column].str.lower()\n",
    "#         df[column] = np.where(df[column] == ' yes',1,0)\n",
    "scaled_cts_covariates = StandardScaler().fit_transform(df[cts_variables_names])\n",
    "binary_covariates = df[binary_variables_names]\n",
    "d = pd.DataFrame(np.concatenate((scaled_cts_covariates, binary_covariates), axis=1), \n",
    "                        columns=cts_variables_names+binary_variables_names, index=df.index)\n",
    "d[\"W\"] = df[\"treatment\"]\n",
    "d[\"Y\"] = df[\"voted\"]\n",
    "\n",
    "gotv_data = resample_from_GOTV(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All dataset ate result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for S learner:  0.04186450070605465\n",
      "rmse: 0.008350676095496454\n"
     ]
    }
   ],
   "source": [
    "s_learner = Slearner(baselearner=RandomForestClassifier(), is_regressor=False)\n",
    "s_learner.fit(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "ite, yhat_ts, yhat_cs, rmse = s_learner.get_ite(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "print('ATE for S learner: ', np.mean(ite))\n",
    "print('rmse:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for T learner:  0.08233968128751823\n",
      "rmse: 0.008607679896763086\n"
     ]
    }
   ],
   "source": [
    "t_learner = Tlearner(RandomForestClassifier(),RandomForestClassifier(), is_regressor= False)\n",
    "t_learner.fit(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "ite, yhat_ts, yhat_cs, rmse = t_learner.get_ite(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "\n",
    "print('ATE for T learner: ', np.mean(ite))\n",
    "print('rmse:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for X learner:  1032.3032128106656\n",
      "rmse: 0.007231897637475376\n"
     ]
    }
   ],
   "source": [
    "x_learner = Xlearner(RandomForestClassifier(),\n",
    "                     propensity_model = LogisticRegression(),\n",
    "                     control_effect_learner = LinearRegression(),\n",
    "                     treatment_effect_learner = LinearRegression(),\n",
    "                    is_regressor= False)\n",
    "x_learner.fit(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "ite, yhat_ts, yhat_cs, rmse = x_learner.get_ite(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "\n",
    "print('ATE for X learner: ', np.mean(ite))\n",
    "print('rmse:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With equal size of treatment/ control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yob</th>\n",
       "      <th>treatment</th>\n",
       "      <th>cluster</th>\n",
       "      <th>hh_id</th>\n",
       "      <th>hh_size</th>\n",
       "      <th>numberofnames</th>\n",
       "      <th>p2004_mean</th>\n",
       "      <th>g2004_mean</th>\n",
       "      <th>sex</th>\n",
       "      <th>g2000</th>\n",
       "      <th>g2002</th>\n",
       "      <th>p2000</th>\n",
       "      <th>p2002</th>\n",
       "      <th>p2004</th>\n",
       "      <th>W</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1.188085</td>\n",
       "      <td>2.237461</td>\n",
       "      <td>-1.727258</td>\n",
       "      <td>-1.727229</td>\n",
       "      <td>-1.498182</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>-1.443668</td>\n",
       "      <td>-2.865244</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.703996</td>\n",
       "      <td>2.237461</td>\n",
       "      <td>-1.727258</td>\n",
       "      <td>-1.727114</td>\n",
       "      <td>-0.233199</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>-1.443668</td>\n",
       "      <td>-1.562139</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-1.672174</td>\n",
       "      <td>2.237461</td>\n",
       "      <td>-1.727258</td>\n",
       "      <td>-1.727114</td>\n",
       "      <td>-0.233199</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>-1.443668</td>\n",
       "      <td>-1.562139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.012441</td>\n",
       "      <td>2.237461</td>\n",
       "      <td>-1.726912</td>\n",
       "      <td>-1.727018</td>\n",
       "      <td>1.031783</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>-0.378716</td>\n",
       "      <td>-0.259034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.609959</td>\n",
       "      <td>2.237461</td>\n",
       "      <td>-1.726912</td>\n",
       "      <td>-1.727018</td>\n",
       "      <td>1.031783</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>-0.378716</td>\n",
       "      <td>-0.259034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344035</th>\n",
       "      <td>-1.810485</td>\n",
       "      <td>2.237461</td>\n",
       "      <td>1.735860</td>\n",
       "      <td>1.735774</td>\n",
       "      <td>-0.233199</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>2.017426</td>\n",
       "      <td>0.392520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344043</th>\n",
       "      <td>0.402492</td>\n",
       "      <td>2.237461</td>\n",
       "      <td>1.735860</td>\n",
       "      <td>1.735870</td>\n",
       "      <td>-1.498182</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>0.153760</td>\n",
       "      <td>-0.259034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344059</th>\n",
       "      <td>-2.640351</td>\n",
       "      <td>2.237461</td>\n",
       "      <td>1.736207</td>\n",
       "      <td>1.736063</td>\n",
       "      <td>-1.498182</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>0.686236</td>\n",
       "      <td>-0.259034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344076</th>\n",
       "      <td>-0.358218</td>\n",
       "      <td>2.237461</td>\n",
       "      <td>1.736207</td>\n",
       "      <td>1.736313</td>\n",
       "      <td>-0.233199</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>0.952474</td>\n",
       "      <td>0.392520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344077</th>\n",
       "      <td>-0.980618</td>\n",
       "      <td>2.237461</td>\n",
       "      <td>1.736207</td>\n",
       "      <td>1.736313</td>\n",
       "      <td>-0.233199</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>0.952474</td>\n",
       "      <td>0.392520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38201 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             yob  treatment   cluster     hh_id   hh_size  numberofnames  \\\n",
       "19     -1.188085   2.237461 -1.727258 -1.727229 -1.498182       0.139749   \n",
       "30     -0.703996   2.237461 -1.727258 -1.727114 -0.233199       0.139749   \n",
       "31     -1.672174   2.237461 -1.727258 -1.727114 -0.233199       0.139749   \n",
       "38     -0.012441   2.237461 -1.726912 -1.727018  1.031783       0.139749   \n",
       "39      0.609959   2.237461 -1.726912 -1.727018  1.031783       0.139749   \n",
       "...          ...        ...       ...       ...       ...            ...   \n",
       "344035 -1.810485   2.237461  1.735860  1.735774 -0.233199       0.139749   \n",
       "344043  0.402492   2.237461  1.735860  1.735870 -1.498182       0.139749   \n",
       "344059 -2.640351   2.237461  1.736207  1.736063 -1.498182       0.139749   \n",
       "344076 -0.358218   2.237461  1.736207  1.736313 -0.233199       0.139749   \n",
       "344077 -0.980618   2.237461  1.736207  1.736313 -0.233199       0.139749   \n",
       "\n",
       "        p2004_mean  g2004_mean  sex  g2000  g2002  p2000  p2002  p2004  W  Y  \n",
       "19       -1.443668   -2.865244  1.0    1.0    1.0    0.0    1.0    0.0  1  1  \n",
       "30       -1.443668   -1.562139  1.0    1.0    1.0    1.0    0.0    0.0  1  0  \n",
       "31       -1.443668   -1.562139  0.0    1.0    1.0    1.0    0.0    0.0  1  0  \n",
       "38       -0.378716   -0.259034  1.0    1.0    1.0    0.0    0.0    1.0  1  1  \n",
       "39       -0.378716   -0.259034  0.0    1.0    1.0    0.0    0.0    1.0  1  1  \n",
       "...            ...         ...  ...    ...    ...    ...    ...    ... .. ..  \n",
       "344035    2.017426    0.392520  1.0    1.0    0.0    0.0    0.0    1.0  1  1  \n",
       "344043    0.153760   -0.259034  1.0    1.0    1.0    0.0    0.0    1.0  1  0  \n",
       "344059    0.686236   -0.259034  0.0    1.0    1.0    1.0    0.0    1.0  1  0  \n",
       "344076    0.952474    0.392520  0.0    1.0    1.0    0.0    1.0    0.0  1  0  \n",
       "344077    0.952474    0.392520  1.0    1.0    1.0    0.0    1.0    0.0  1  0  \n",
       "\n",
       "[38201 rows x 16 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[d['W'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yob</th>\n",
       "      <th>treatment</th>\n",
       "      <th>cluster</th>\n",
       "      <th>hh_id</th>\n",
       "      <th>hh_size</th>\n",
       "      <th>numberofnames</th>\n",
       "      <th>p2004_mean</th>\n",
       "      <th>g2004_mean</th>\n",
       "      <th>sex</th>\n",
       "      <th>g2000</th>\n",
       "      <th>g2002</th>\n",
       "      <th>p2000</th>\n",
       "      <th>p2002</th>\n",
       "      <th>p2004</th>\n",
       "      <th>W</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.716448</td>\n",
       "      <td>-0.446935</td>\n",
       "      <td>-1.727258</td>\n",
       "      <td>-1.727383</td>\n",
       "      <td>1.031783</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>-1.443668</td>\n",
       "      <td>-0.259034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.195026</td>\n",
       "      <td>-0.446935</td>\n",
       "      <td>-1.727258</td>\n",
       "      <td>-1.727383</td>\n",
       "      <td>1.031783</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>-1.443668</td>\n",
       "      <td>-0.259034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.012441</td>\n",
       "      <td>-0.446935</td>\n",
       "      <td>-1.727258</td>\n",
       "      <td>-1.727383</td>\n",
       "      <td>1.031783</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>-1.443668</td>\n",
       "      <td>-0.259034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.817426</td>\n",
       "      <td>-0.446935</td>\n",
       "      <td>-1.727258</td>\n",
       "      <td>-1.727364</td>\n",
       "      <td>-0.233199</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>-1.443668</td>\n",
       "      <td>-0.259034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.748270</td>\n",
       "      <td>-0.446935</td>\n",
       "      <td>-1.727258</td>\n",
       "      <td>-1.727364</td>\n",
       "      <td>-0.233199</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>-1.443668</td>\n",
       "      <td>-0.259034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344079</th>\n",
       "      <td>-0.911463</td>\n",
       "      <td>-0.446935</td>\n",
       "      <td>1.736207</td>\n",
       "      <td>1.736332</td>\n",
       "      <td>-0.233199</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>0.952474</td>\n",
       "      <td>0.392520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344080</th>\n",
       "      <td>-0.081596</td>\n",
       "      <td>-0.446935</td>\n",
       "      <td>1.736207</td>\n",
       "      <td>1.736351</td>\n",
       "      <td>-0.233199</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>-0.378716</td>\n",
       "      <td>-0.910586</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344081</th>\n",
       "      <td>0.125870</td>\n",
       "      <td>-0.446935</td>\n",
       "      <td>1.736207</td>\n",
       "      <td>1.736351</td>\n",
       "      <td>-0.233199</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>-0.378716</td>\n",
       "      <td>-0.910586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344082</th>\n",
       "      <td>-1.326396</td>\n",
       "      <td>-0.446935</td>\n",
       "      <td>1.736207</td>\n",
       "      <td>1.736371</td>\n",
       "      <td>-0.233199</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>0.153760</td>\n",
       "      <td>-0.910586</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344083</th>\n",
       "      <td>-0.496530</td>\n",
       "      <td>-0.446935</td>\n",
       "      <td>1.736207</td>\n",
       "      <td>1.736371</td>\n",
       "      <td>-0.233199</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>0.153760</td>\n",
       "      <td>-0.910586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191243 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             yob  treatment   cluster     hh_id   hh_size  numberofnames  \\\n",
       "5       1.716448  -0.446935 -1.727258 -1.727383  1.031783       0.139749   \n",
       "6       0.195026  -0.446935 -1.727258 -1.727383  1.031783       0.139749   \n",
       "7      -0.012441  -0.446935 -1.727258 -1.727383  1.031783       0.139749   \n",
       "8       0.817426  -0.446935 -1.727258 -1.727364 -0.233199       0.139749   \n",
       "9       0.748270  -0.446935 -1.727258 -1.727364 -0.233199       0.139749   \n",
       "...          ...        ...       ...       ...       ...            ...   \n",
       "344079 -0.911463  -0.446935  1.736207  1.736332 -0.233199       0.139749   \n",
       "344080 -0.081596  -0.446935  1.736207  1.736351 -0.233199       0.139749   \n",
       "344081  0.125870  -0.446935  1.736207  1.736351 -0.233199       0.139749   \n",
       "344082 -1.326396  -0.446935  1.736207  1.736371 -0.233199       0.139749   \n",
       "344083 -0.496530  -0.446935  1.736207  1.736371 -0.233199       0.139749   \n",
       "\n",
       "        p2004_mean  g2004_mean  sex  g2000  g2002  p2000  p2002  p2004  W  Y  \n",
       "5        -1.443668   -0.259034  1.0    0.0    0.0    0.0    0.0    0.0  0  0  \n",
       "6        -1.443668   -0.259034  0.0    1.0    1.0    0.0    1.0    0.0  0  1  \n",
       "7        -1.443668   -0.259034  1.0    1.0    1.0    0.0    1.0    0.0  0  1  \n",
       "8        -1.443668   -0.259034  0.0    0.0    0.0    0.0    1.0    0.0  0  0  \n",
       "9        -1.443668   -0.259034  1.0    1.0    1.0    0.0    1.0    0.0  0  0  \n",
       "...            ...         ...  ...    ...    ...    ...    ...    ... .. ..  \n",
       "344079    0.952474    0.392520  1.0    1.0    1.0    0.0    1.0    1.0  0  1  \n",
       "344080   -0.378716   -0.910586  1.0    1.0    1.0    1.0    0.0    1.0  0  0  \n",
       "344081   -0.378716   -0.910586  0.0    1.0    0.0    0.0    0.0    0.0  0  0  \n",
       "344082    0.153760   -0.910586  1.0    1.0    1.0    1.0    1.0    1.0  0  1  \n",
       "344083    0.153760   -0.910586  0.0    1.0    1.0    0.0    0.0    1.0  0  1  \n",
       "\n",
       "[191243 rows x 16 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[d['W'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_w0, d_w1  = gotv_data.get_treat_control_equalsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.concat([d_w0,d_w1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for S learner:  0.033004\n"
     ]
    }
   ],
   "source": [
    "s_learner = Slearner(baselearner=RandomForestClassifier(), is_regressor=False)\n",
    "s_learner.fit(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "ite, yhat_ts, yhat_cs, rmse = s_learner.get_ite(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "print('ATE for S learner: ', np.mean(ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for T learner:  0.068063\n"
     ]
    }
   ],
   "source": [
    "t_learner = Tlearner(RandomForestClassifier(),RandomForestClassifier(), is_regressor= False)\n",
    "t_learner.fit(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "ite, yhat_ts, yhat_cs, rmse = t_learner.get_ite(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "\n",
    "print('ATE for T learner: ', np.mean(ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for X learner:  -7.695425515984699\n"
     ]
    }
   ],
   "source": [
    "x_learner = Xlearner(RandomForestClassifier(),\n",
    "                     propensity_model = LogisticRegression(),\n",
    "                     control_effect_learner = LinearRegression(),\n",
    "                     treatment_effect_learner = LinearRegression(),\n",
    "                    is_regressor= False)\n",
    "x_learner.fit(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "ite, yhat_ts, yhat_cs, rmse = x_learner.get_ite(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "\n",
    "print('ATE for X learner: ', np.mean(ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  to verify if X learner is the best estimator, lets run experiment 10 times, get the avg values of ate for three\n",
    "# learnaers\n",
    "\n",
    "s_ates = []\n",
    "t_ates = []\n",
    "x_ates = []\n",
    "for _ in range(10):\n",
    "    # resample 10000 data \n",
    "    d_w0, d_w1  = gotv_data.get_treat_control_equalsize(n_sample=10000)\n",
    "    d = pd.concat([d_w0,d_w1])\n",
    "    \n",
    "    s_learner = Slearner(baselearner=RandomForestClassifier(), is_regressor=False)\n",
    "    s_learner.fit(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "    ite, yhat_ts, yhat_cs, rmse = s_learner.get_ite(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "    s_ates.append(np.mean(ite))\n",
    "    \n",
    "    \n",
    "    t_learner = Tlearner(RandomForestClassifier(),RandomForestClassifier(), is_regressor= False)\n",
    "    t_learner.fit(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "    ite, yhat_ts, yhat_cs, rmse = t_learner.get_ite(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "    t_ates.append(np.mean(ite))\n",
    "\n",
    "\n",
    "    x_learner = Xlearner(RandomForestClassifier(),\n",
    "                     propensity_model = LogisticRegression(),\n",
    "                     control_effect_learner = LinearRegression(),\n",
    "                     treatment_effect_learner = LinearRegression(),\n",
    "                    is_regressor= False)\n",
    "    x_learner.fit(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "    ite, yhat_ts, yhat_cs, rmse = x_learner.get_ite(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "    x_ates.append(np.mean(ite))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimator</th>\n",
       "      <th>ATE_Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Slearner</td>\n",
       "      <td>0.036314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tlearner</td>\n",
       "      <td>0.080295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xlearner</td>\n",
       "      <td>6.277162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Estimator  ATE_Mean\n",
       "0  Slearner  0.036314\n",
       "1  Tlearner  0.080295\n",
       "2  Xlearner  6.277162"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame()\n",
    "result['Estimator'] = ['Slearner','Tlearner','Xlearner']\n",
    "result['ATE_Mean'] = [np.mean(s_ates),np.mean(t_ates),np.mean(x_ates)]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With diff size of treatment/ control (0.01 treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_w0, d_w1  = gotv_data.get_treat_control_diffsize(n_sample= 10000,ratio= 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.concat([d_w0,d_w1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for S learner:  0.024999\n"
     ]
    }
   ],
   "source": [
    "s_learner = Slearner(baselearner=RandomForestClassifier(), is_regressor=False)\n",
    "s_learner.fit(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "ite, yhat_ts, yhat_cs, rmse = s_learner.get_ite(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "print('ATE for S learner: ', np.mean(ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for T learner:  0.060592999999999994\n"
     ]
    }
   ],
   "source": [
    "t_learner = Tlearner(RandomForestClassifier(),RandomForestClassifier(), is_regressor= False)\n",
    "t_learner.fit(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "ite, yhat_ts, yhat_cs, rmse = t_learner.get_ite(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "\n",
    "print('ATE for T learner: ', np.mean(ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE for X learner:  29.582934821209165\n"
     ]
    }
   ],
   "source": [
    "x_learner = Xlearner(RandomForestClassifier(),\n",
    "                     propensity_model = LogisticRegression(),\n",
    "                     control_effect_learner = LinearRegression(),\n",
    "                     treatment_effect_learner = LinearRegression(),\n",
    "                    is_regressor= False)\n",
    "x_learner.fit(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "ite, yhat_ts, yhat_cs, rmse = x_learner.get_ite(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "\n",
    "print('ATE for X learner: ', np.mean(ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  to verify if X learner is the best estimator, lets run experiment 10 times, get the avg values of ate for three\n",
    "# learnaers\n",
    "\n",
    "s_ates = []\n",
    "t_ates = []\n",
    "x_ates = []\n",
    "for _ in range(10):\n",
    "    # resample 10000 data \n",
    "    d_w0, d_w1  = gotv_data.get_treat_control_diffsize(n_sample= 10000,ratio= 0.01)\n",
    "    d = pd.concat([d_w0,d_w1])\n",
    "    \n",
    "    s_learner = Slearner(baselearner=RandomForestClassifier(), is_regressor=False)\n",
    "    s_learner.fit(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "    ite, yhat_ts, yhat_cs, rmse = s_learner.get_ite(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "    s_ates.append(np.mean(ite))\n",
    "    \n",
    "    \n",
    "    t_learner = Tlearner(RandomForestClassifier(),RandomForestClassifier(), is_regressor= False)\n",
    "    t_learner.fit(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "    ite, yhat_ts, yhat_cs, rmse = t_learner.get_ite(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "    t_ates.append(np.mean(ite))\n",
    "\n",
    "\n",
    "    x_learner = Xlearner(RandomForestClassifier(),\n",
    "                     propensity_model = LogisticRegression(),\n",
    "                     control_effect_learner = LinearRegression(),\n",
    "                     treatment_effect_learner = LinearRegression(),\n",
    "                    is_regressor= False)\n",
    "    x_learner.fit(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "    ite, yhat_ts, yhat_cs, rmse = x_learner.get_ite(d.drop(columns = ['W','Y']), d['W'], d['Y'])\n",
    "    x_ates.append(np.mean(ite))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimator</th>\n",
       "      <th>ATE_Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Slearner</td>\n",
       "      <td>0.026003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tlearner</td>\n",
       "      <td>0.064725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xlearner</td>\n",
       "      <td>-120.004440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Estimator    ATE_Mean\n",
       "0  Slearner    0.026003\n",
       "1  Tlearner    0.064725\n",
       "2  Xlearner -120.004440"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame()\n",
    "result['Estimator'] = ['Slearner','Tlearner','Xlearner']\n",
    "result['ATE_Mean'] = [np.mean(s_ates),np.mean(t_ates),np.mean(x_ates)]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
